/*
 * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
 * or more contributor license agreements. Licensed under the Elastic License
 * 2.0 and the Server Side Public License, v 1; you may not use this file except
 * in compliance with, at your election, the Elastic License 2.0 or the Server
 * Side Public License, v 1.
 */

const { join } = require('path');
const { ESLint } = require('eslint');
const partition = require('lodash/partition');
const { readdirSync, readFileSync, writeFileSync } = require('fs');
const ora = require('ora');
const log = ora('Updating ES|QL AST walker from antlr grammar').start();

async function execute() {
  const generatedAntlrFolder = join(__dirname, '..', 'src', 'antlr');

  const generatedAntlrFolderContents = readdirSync(generatedAntlrFolder);

  const tokenRegex = /public static readonly (?<name>[A-Z_]*(UN)*QUOTED_[A-Z_]+) = (?<value>\d+);/;
  const lexerFile = generatedAntlrFolderContents.find((file) => file === 'esql_parser.ts');
  const lexerFileRows = readFileSync(join(generatedAntlrFolder, lexerFile), 'utf8')
    .toString()
    .split('\n');
  const tokenList = [];
  for (const row of lexerFileRows) {
    const match = row.match(tokenRegex);
    if (match?.groups) {
      tokenList.push(match.groups);
    }
  }
  const [unquotedList, quotedList] = partition(tokenList, ({ name }) => /UNQUOTED/.test(name));

  // now all quote/unquoted tokens are registered
  // dump them into the ast_helper file
  const astHelperFileFolder = join(__dirname, '..', 'src');
  const astHelperFilename = 'ast_helpers.ts';

  try {
    const astHelperContentRows = readFileSync(join(astHelperFileFolder, astHelperFilename), 'utf8')
      .toString()
      .split('\n');

    const startAutoGeneratedComment = astHelperContentRows.findIndex(
      (row) => row === '/* SCRIPT_MARKER_START */'
    );
    const endAutoGeneratedComment =
      astHelperContentRows.findIndex((row) => row === '/* SCRIPT_MARKER_END */') + 1;

    const newFunctionsContent = `
/* SCRIPT_MARKER_START */
function getQuotedText(ctx: ParserRuleContext) {
    return [
        ${quotedList.map(({ name, value }) => `${value} /* esql_parser.${name} */`).join(', ')}
    ]
        .map((keyCode) => ctx.getToken(keyCode, 0))
        .filter(nonNullable)[0];
    }
    
function getUnquotedText(ctx: ParserRuleContext) {
    return [
        ${unquotedList.map(({ name, value }) => `${value} /* esql_parser.${name} */`).join(', ')}

    ]
        .map((keyCode) => ctx.getToken(keyCode, 0))
        .filter(nonNullable)[0];
}
/* SCRIPT_MARKER_END */
`;

    const fileContent = astHelperContentRows
      .slice(0, startAutoGeneratedComment)
      .concat(newFunctionsContent.split('\n'), astHelperContentRows.slice(endAutoGeneratedComment));

    const fileContentString = fileContent.join('\n');

    const eslint = new ESLint({
      fix: true,
      overrideConfig: {
        parser: '@typescript-eslint/parser',
        parserOptions: {
          sourceType: 'module',
          ecmaVersion: 2018,
        },
        rules: {
          '@kbn/imports/no_unresolvable_imports': 'off',
          'prettier/prettier': [
            'error',
            {
              parser: 'typescript',
            },
          ],
        },
      },
    });

    const results = await eslint.lintText(fileContentString);

    if (results.some(({ messages }) => messages.length > 0)) {
      const formatter = await eslint.loadFormatter('stylish');
      const resultText = formatter.format(results);
      process.exitCode = 1;
      return log.fail(resultText);
    }

    const filePath = join(astHelperFileFolder, astHelperFilename);
    writeFileSync(filePath, results[0].output || '', { encoding: 'utf8' });
  } catch (err) {
    return log.fail(err.message);
  }

  log.succeed('Updated ES|QL helper from antlr grammar successfully');
}

execute();
