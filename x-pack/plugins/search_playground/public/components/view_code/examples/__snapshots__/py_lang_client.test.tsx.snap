// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`PY_LANG_CLIENT function renders with correct content 1`] = `
"## Install the required packages
## pip install -qU elasticsearch openai

import os
from elasticsearch import Elasticsearch
from openai import OpenAI


es_client = Elasticsearch(
  http://my-local-cloud-instance,
  api_key=os.environ[\\"ES_API_KEY\\"]
)
      

openai_client = OpenAI(
  api_key=os.environ[\\"OPENAI_API_KEY\\"],
)

def get_elasticsearch_results(query):
  es_query = {}

  result = es.search(index=\\"index1,index2\\", query=es_query, size=10)
  return result[\\"hits\\"][\\"hits\\"]

def create_openai_prompt(question, results):

  context = \\"\\"
  index_source_fields = {
  \\"index1\\": [
    \\"field1\\"
  ],
  \\"index2\\": [
    \\"field2\\"
  ]
}
  for hit in results:
    source_field = index_source_fields.get(hit[\\"_index\\"])[0]
    hit_context = hit[\\"_source\\"][source_field]
    context += f\\"{hit_context}
\\"

  prompt = f\\"\\"\\"
  Instructions:
  
  - Your prompt
  - Answer questions truthfully and factually using only the information presented.
  - If you don't know the answer, just say that you don't know, don't make up an answer!
  - You must always cite the document where the answer was extracted using inline academic citation style [], using the position.
  - Use markdown format for code examples.
  - You are correct, factual, precise, and reliable.
  

  Context:
  {context}

  Question: {question}
  Answer:
  \\"\\"\\"

  return prompt

def generate_openai_completion(user_prompt):
  response = openai_client.chat.completions.create(
    model=\\"Your-new-model\\",
    messages=[
        {\\"role\\": \\"system\\", \\"content\\": \\"You are an assistant for question-answering tasks.\\"},
        {\\"role\\": \\"user\\", \\"content\\": user_prompt},
    ]
  )

  return response.choices[0].message.content

if __name__ == \\"__main__\\":
    question = \\"my question\\"

    elasticsearch_results = get_elasticsearch_results(question)

    context_prompt = create_openai_prompt(question, elasticsearch_results)

    openai_completion = generate_openai_completion(context_prompt)

    print(openai_completion)

"
`;
