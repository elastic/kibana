# Click the run button of each step to enable the module
# Upload scripts
# 1. Script to assign risk level based on risk score
PUT _scripts/ml_userriskscore_levels_script
{
  "script": {
    "lang": "painless",
    "source": "double risk_score = (def)ctx.getByPath(params.risk_score);\nif (risk_score < 20) {\n  ctx['user']['risk']['calculated_level'] = 'Unknown'\n}\nelse if (risk_score >= 20 && risk_score < 40) {\n  ctx['user']['risk']['calculated_level'] = 'Low'\n}\nelse if (risk_score >= 40 && risk_score < 70) {\n  ctx['user']['risk']['calculated_level'] = 'Moderate'\n}\nelse if (risk_score >= 70 && risk_score < 90) {\n  ctx['user']['risk']['calculated_level'] = 'High'\n}\nelse if (risk_score >= 90) {\n  ctx['user']['risk']['calculated_level'] = 'Critical'\n}"
  }
}

# 2. Map script for the User Risk Score transform
PUT _scripts/ml_userriskscore_map_script
{
  "script": {
    "lang": "painless", "source": "// Get running sum of risk score per rule name per shard\\\\\nString rule_name = doc[\"signal.rule.name\"].value;\ndef stats = state.rule_risk_stats.getOrDefault(rule_name, 0.0);\nstats = doc[\"signal.rule.risk_score\"].value;\nstate.rule_risk_stats.put(rule_name, stats);"
  }
}

# 3. Reduce script for the User Risk Score transform
PUT _scripts/ml_userriskscore_reduce_script
{
  "script": {
    "lang": "painless",
    "source": "// Consolidating time decayed risks from across all shards\nMap total_risk_stats = new HashMap();\nfor (state in states) {\n    for (key in state.rule_risk_stats.keySet()) {\n    def rule_stats = state.rule_risk_stats.get(key);\n    def stats = total_risk_stats.getOrDefault(key, 0.0);\n    stats = rule_stats;\n    total_risk_stats.put(key, stats);\n    }\n}\n// Consolidating individual rule risks and arranging them in decreasing order\nList risks = new ArrayList();\nfor (key in total_risk_stats.keySet()) {\n    risks.add(total_risk_stats[key])\n}\nCollections.sort(risks, Collections.reverseOrder());\n// Calculating total risk and normalizing it to a range\ndouble total_risk = 0.0;\ndouble risk_cap = params.max_risk * params.zeta_constant;\nfor (int i=0;i<risks.length;i++) {\n    total_risk += risks[i] / Math.pow((1+i), params.p);\n}\ndouble total_norm_risk = 100 * total_risk / risk_cap;\nif (total_norm_risk < 40) {\n    total_norm_risk =  2.125 * total_norm_risk;\n}\nelse if (total_norm_risk >= 40 && total_norm_risk < 50) {\n    total_norm_risk = 85 + (total_norm_risk - 40);\n}\nelse {\n    total_norm_risk = 95 + (total_norm_risk - 50) / 10;\n}\n\nList rule_stats = new ArrayList();\nfor (key in total_risk_stats.keySet()) {\n    Map temp = new HashMap();\n    temp[\"rule_name\"] = key;\n    temp[\"rule_risk\"] = total_risk_stats[key];\n    rule_stats.add(temp);\n}\n\nreturn [\"calculated_score_norm\": total_norm_risk, \"rule_risks\": rule_stats];"
  }
}

# 4. Upload ingest pipeline
# Ingest pipeline to add ingest timestamp and risk level to documents
PUT _ingest/pipeline/ml_userriskscore_ingest_pipeline
{
  "processors": [
    {
      "set": {
        "field": "ingest_timestamp",
        "value": "{{_ingest.timestamp}}"
      }
    },
    {
      "fingerprint": {
        "fields": [
          "@timestamp",
          "_id"
        ],
        "method": "SHA-256",
        "target_field": "_id"
      }
    },
    {
      "script": {
        "id": "ml_userriskscore_levels_script",
        "params": {
          "risk_score": "user.risk.calculated_score_norm"
        }
      }
    }
  ]
}

# 5. Create mappings for the destination index of the User Risk Score pivot transform
PUT ml_user_risk_score_{{space_name}}
{
  "mappings": {
    "properties": {
      "user": {
        "properties": {
          "name": {
            "type": "keyword"
          },
          "risk": {
            "properties": {
              "calculated_score_norm": {
                "type": "float"
              },
              "calculated_level": {
                "type": "keyword"
              },
              "rule_risks": {
                "properties": {
                  "rule_name": {
                    "type": "text",
                    "fields": {
                      "keyword": {
                        "type": "keyword"
                      }
                    }
                  },
                  "rule_risk": {
                    "type": "float"
                  },
                  "rule_id": {
                    "type": "keyword"
                  }
                }
              }
            }
          }
        }
      },
      "ingest_timestamp": {
        "type": "date"
      },
      "@timestamp": {
        "type": "date"
      }
    }
  }
}

# 6. Upload the User Risk Score pivot transform
# This transform runs hourly and calculates a risk score and risk level for users in a Kibana space
PUT _transform/ml_userriskscore_pivot_transform_{{space_name}}
{
  "dest": {
    "index": "ml_user_risk_score_{{space_name}}",
    "pipeline": "ml_userriskscore_ingest_pipeline"
  },
  "frequency": "1h",
  "pivot": {
    "aggregations": {
      "@timestamp": {
        "max": {
          "field": "@timestamp"
        }
      },
      "user.risk": {
        "scripted_metric": {
          "combine_script": "return state",
          "init_script": "state.rule_risk_stats = new HashMap();",
          "map_script": {
            "id": "ml_userriskscore_map_script"
          },
          "params": {
            "max_risk": 100,
            "p": 1.5,
            "zeta_constant": 2.612
          },
          "reduce_script": {
            "id": "ml_userriskscore_reduce_script"
          }
        }
      }
    },
    "group_by": {
      "user.name": {
        "terms": {
          "field": "user.name"
        }
      }
    }
  },
  "source": {
    "index": [
      ".alerts-security.alerts-{{space_name}}"
    ],
    "query": {
      "bool": {
        "filter": [
          {
            "range": {
              "@timestamp": {
                "gte": "now-90d"
              }
            }
          },
          {
            "match": {
              "signal.status": "open"
            }
          }
        ]
      }
    }
  },
  "sync": {
    "time": {
      "delay": "120s",
      "field": "@timestamp"
    }
  }
}

# 7. start the pivot transform
POST _transform/ml_userriskscore_pivot_transform_{{space_name}}/_start

# 8. Create mappings for the destination index of the User Risk Score latest transform
PUT ml_user_risk_score_latest_{{space_name}}
{
  "mappings": {
    "properties": {
      "user": {
        "properties": {
          "name": {
            "type": "keyword"
          },
          "risk": {
            "properties": {
              "calculated_score_norm": {
                "type": "float"
              },
              "calculated_level": {
                "type": "keyword"
              },
              "rule_risks": {
                "properties": {
                  "rule_name": {
                    "type": "text",
                    "fields": {
                      "keyword": {
                        "type": "keyword"
                      }
                    }
                  },
                  "rule_risk": {
                    "type": "float"
                  },
                  "rule_id": {
                    "type": "keyword"
                  }
                }
              }
            }
          }
        }
      },
      "ingest_timestamp": {
        "type": "date"
      },
      "@timestamp": {
        "type": "date"
      }
    }
  }
}

# 9. Upload the latest transform
# This transform gets the latest risk information about users in a Kibana space
PUT _transform/ml_userriskscore_latest_transform_{{space_name}}
{
  "dest": {
    "index": "ml_user_risk_score_latest_{{space_name}}"
  },
  "frequency": "1h",
  "latest": {
    "sort": "@timestamp",
    "unique_key": [
      "user.name"
    ]
  },
  "source": {
    "index": [
      "ml_user_risk_score_{{space_name}}"
    ]
  },
  "sync": {
    "time": {
      "delay": "2s",
      "field": "ingest_timestamp"
    }
  }
}

# 10. Start the latest transform
POST _transform/ml_userriskscore_latest_transform_{{space_name}}/_start

# Hint: If you don't see data after running any of the transforms, stop and restart the transforms
# Stop the pivot transform
POST _transform/ml_userriskscore_pivot_transform_{{space_name}}/_stop

# Start the pivot transform
POST _transform/ml_userriskscore_pivot_transform_{{space_name}}/_start

# Stop the latest transform
POST _transform/ml_userriskscore_latest_transform_{{space_name}}/_stop

# Start the latest transform
POST _transform/ml_userriskscore_latest_transform_{{space_name}}/_start
