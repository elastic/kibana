// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`PY_LANG_CLIENT function renders with correct content 1`] = `
"## Install the required packages
## pip install -qU elasticsearch openai

import os
from elasticsearch import Elasticsearch
from openai import OpenAI


es_client = Elasticsearch(
    \\"http://my-local-cloud-instance\\",
    api_key=os.environ[\\"ES_API_KEY\\"]
)
      

openai_client = OpenAI(
    api_key=os.environ[\\"OPENAI_API_KEY\\"],
)

index_source_fields = {
    \\"index1\\": [
        \\"field1\\"
    ],
    \\"index2\\": [
        \\"field2\\"
    ]
}

def get_elasticsearch_results(query):
    es_query = {
        \\"query\\": {},
        \\"size\\": 10
    }

    result = es_client.search(index=\\"index1,index2\\", body=es_query)
    return result[\\"hits\\"][\\"hits\\"]

def create_openai_prompt(results):
    context = \\"\\"
    for hit in results:
        ## For semantic_text matches, we need to extract the text from the highlighted field
        if \\"highlight\\" in hit:
            highlighted_texts = []
            for values in hit[\\"highlight\\"].values():
                highlighted_texts.extend(values)
            context += \\"\\\\n --- \\\\n\\".join(highlighted_texts)
        else:
            context_fields = index_source_fields.get(hit[\\"_index\\"])
            for source_field in context_fields:
                hit_context = hit[\\"_source\\"][source_field]
                if hit_context:
                    context += f\\"{source_field}: {hit_context}\\\\n\\"
    prompt = f\\"\\"\\"
  Instructions:
  
  - Your prompt
  - Answer questions truthfully and factually using only the context presented.
  - If you don't know the answer, just say that you don't know, don't make up an answer.
  - You must always cite the document where the answer was extracted using inline academic citation style [], using the position.
  - Use markdown format for code examples.
  - You are correct, factual, precise, and reliable.
  

  Context:
  {context}

  
  \\"\\"\\"

    return prompt

def generate_openai_completion(user_prompt, question):
    response = openai_client.chat.completions.create(
        model=\\"gpt-3.5-turbo\\",
        messages=[
            {\\"role\\": \\"system\\", \\"content\\": user_prompt},
            {\\"role\\": \\"user\\", \\"content\\": question},
        ]
    )

    return response.choices[0].message.content

if __name__ == \\"__main__\\":
    question = \\"my question\\"
    elasticsearch_results = get_elasticsearch_results(question)
    context_prompt = create_openai_prompt(elasticsearch_results)
    openai_completion = generate_openai_completion(context_prompt, question)
    print(openai_completion)

"
`;

exports[`PY_LANG_CLIENT function renders with correct content for multiple context fields 1`] = `
"## Install the required packages
## pip install -qU elasticsearch openai

import os
from elasticsearch import Elasticsearch
from openai import OpenAI


es_client = Elasticsearch(
    \\"http://my-local-cloud-instance\\",
    api_key=os.environ[\\"ES_API_KEY\\"]
)
      

openai_client = OpenAI(
    api_key=os.environ[\\"OPENAI_API_KEY\\"],
)

index_source_fields = {
    \\"index1\\": [
        \\"field1\\",
        \\"field3\\",
        \\"field4\\"
    ],
    \\"index2\\": [
        \\"field2\\"
    ]
}

def get_elasticsearch_results(query):
    es_query = {
        \\"query\\": {},
        \\"size\\": 10
    }

    result = es_client.search(index=\\"index1,index2\\", body=es_query)
    return result[\\"hits\\"][\\"hits\\"]

def create_openai_prompt(results):
    context = \\"\\"
    for hit in results:
        ## For semantic_text matches, we need to extract the text from the highlighted field
        if \\"highlight\\" in hit:
            highlighted_texts = []
            for values in hit[\\"highlight\\"].values():
                highlighted_texts.extend(values)
            context += \\"\\\\n --- \\\\n\\".join(highlighted_texts)
        else:
            context_fields = index_source_fields.get(hit[\\"_index\\"])
            for source_field in context_fields:
                hit_context = hit[\\"_source\\"][source_field]
                if hit_context:
                    context += f\\"{source_field}: {hit_context}\\\\n\\"
    prompt = f\\"\\"\\"
  Instructions:
  
  - Your prompt
  - Answer questions truthfully and factually using only the context presented.
  - If you don't know the answer, just say that you don't know, don't make up an answer.
  - You must always cite the document where the answer was extracted using inline academic citation style [], using the position.
  - Use markdown format for code examples.
  - You are correct, factual, precise, and reliable.
  

  Context:
  {context}

  
  \\"\\"\\"

    return prompt

def generate_openai_completion(user_prompt, question):
    response = openai_client.chat.completions.create(
        model=\\"gpt-3.5-turbo\\",
        messages=[
            {\\"role\\": \\"system\\", \\"content\\": user_prompt},
            {\\"role\\": \\"user\\", \\"content\\": question},
        ]
    )

    return response.choices[0].message.content

if __name__ == \\"__main__\\":
    question = \\"my question\\"
    elasticsearch_results = get_elasticsearch_results(question)
    context_prompt = create_openai_prompt(elasticsearch_results)
    openai_completion = generate_openai_completion(context_prompt, question)
    print(openai_completion)

"
`;
