# RFC: Alert telemetry to track customized rule fields <!-- omit from toc -->

**Author(s)**: @dplumlee
**Status**: Approved
**Created**: August 4 2025
**Reviewers**: @security-detection-rule-management, @security-detection-engine, @marshallmain

## Summary <!-- omit from toc -->

This RFC is being written to gather comments about different approaches towards enhancing our alert telemetry data. Currently, we collect alert telemetry from prebuilt rules to gather metrics for rule tuning and global threat reports, but when certain rule fields are customized, this data can become skewed and less reliable. We're aiming to add this context to the existing alert telemetry snapshots so that we can filter alerts from rules with certain edited fields out of the overall metrics data.

## Table of contents <!-- omit from toc -->

<!--
Please use the "Markdown All in One" VS Code extension to keep the TOC in sync with the text:
https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one
-->

- [Background \& Context](#background--context)
  - [Why this alert telemetry is needed](#why-this-alert-telemetry-is-needed)
  - [Why this alert telemetry needs to contain information about which fields are customized](#why-this-alert-telemetry-needs-to-contain-information-about-which-fields-are-customized)
  - [What existing tools do we have at our disposal?](#what-existing-tools-do-we-have-at-our-disposal)
  - [Calculating the rule diff for alert objects in snapshot telemetry](#calculating-the-rule-diff-for-alert-objects-in-snapshot-telemetry)
  - [An overview of the `calculateRuleDiff` function and its performance issues](#an-overview-of-the-calculaterulediff-function-and-its-performance-issues)
- [Problem Statement](#problem-statement)
- [Goals](#goals)
- [Non-Goals](#non-goals)
- [Rejected Solutions](#rejected-solutions)
  - [Calculating the rule diff during rule execution](#calculating-the-rule-diff-during-rule-execution)
  - [Using a hash of functional fields to quickly compare changes](#using-a-hash-of-functional-fields-to-quickly-compare-changes)
- [Proposed Solution: Adding a field to the rule schema to track specific customized fields](#proposed-solution-adding-a-field-to-the-rule-schema-to-track-specific-customized-fields)
  - [Approach and technical details](#approach-and-technical-details)
  - [Missing base versions](#missing-base-versions)
  - [Rule customization diff return value proposal](#rule-customization-diff-return-value-proposal)
  - [Functional field definition](#functional-field-definition)
  - [Schema definitions](#schema-definitions)
  - [Examples](#examples)
  - [Pros \& Cons](#pros--cons)
  - [Complexity \& Cost](#complexity--cost)
- [Appendix](#appendix)
  - [Defining functional rule fields](#defining-functional-rule-fields)

## Background & Context

**Related tickets**:

- [Telemetry for detection alerts to keep track of customized rule fields](https://github.com/elastic/security-team/issues/12507) (primary ticket)
- [Collect usage statistics for prebuilt rule customization](https://github.com/elastic/kibana/issues/140369)

### Why this alert telemetry is needed

With the implementation of prebuilt rule customization, users are now able to edit almost every field in their prebuilt rules, including functionally dependent fields such as `query`, `filters`, etc. (see full list in the appendix below), which have the potential to change which alerts are generated by the rule. As it exists now, the alert telemetry we gather from users' environments contains limited information about the rule itself, and there is no way to see if the rule is customized at all, let alone which specific fields have been customized. 

We use this alert telemetry in a few different ways, the most notable of which is the TRaDE team's research on how best to tune the rules for threat coverage. We also use it to build the [global threat report](https://www.elastic.co/resources/security/report/global-threat-report) the company releases every year. The current lack of rule customization context in the alert telemetry makes it impossible to distinguish between alerts from unmodified rules and alerts from modified rules, which have the potential to skew this data, leading to less reliable insights gathered. 

For instance, if a rule's query was modified to better suit a user's need to find threats, it could generate vastly different results than the original query would have. With no way to reconcile these changes from a telemetry point of view, the alerts being generated by a different query are looped in with the rest of the unmodified rules' alerts and we are no longer able to trust the collected alerts are being written from the same logic.

### Why this alert telemetry needs to contain information about which fields are customized

The quick solution would be to add the existing `rule_source` field to the alert telemetry [included rule fields](https://github.com/elastic/kibana/blob/0ad59fab8835d67b476ffbdb82850649e70ab4d9/x-pack/solutions/security/plugins/security_solution/server/lib/telemetry/filterlists/prebuilt_rules_alerts.ts), create filters off that, and be done with it. This would unfortunately be too crude of a solution, and would filter out many valuable alerts that have no difference than those generated by an unmodified rules. 

Only customized functional fields - fields that have the ability to modify which alerts are written by a rule - are cause for concern when collecting this alert telemetry data. If a user were to customize a non-functional field such as `tags` or `note`, it would have no influence on the alerts generated by a rule; they're fields that users often change just for workflow management reasons. Changing a functional field, however, like `query`, has ramifications on which events the rule creates alerts from. As stated before, it could generate drastically different results than that of the original, unmodified prebuilt rule which, while probably beneficial to the user, would be entirely unhelpful for our telemetry data that's assuming the original `query` field is being used.

Because of this difference, we need to collect information from the rule that not only tells us that the rule is customized, but also *how* the rule is customized. From that, we can filter telemetry alerts at a more granular, per-field level, allowing us to still utilize data from customized prebuilt rules.

### What existing tools do we have at our disposal?

As mentioned earlier, we already collect prebuilt rule alert telemetry from real customers in the field. This telemetry is sanitized for performance and privacy reasons through an [allowlist](https://github.com/elastic/kibana/blob/0ad59fab8835d67b476ffbdb82850649e70ab4d9/x-pack/solutions/security/plugins/security_solution/server/lib/telemetry/filterlists/prebuilt_rules_alerts.ts) and collected every hour by [this task](https://github.com/elastic/kibana/blob/06f5a860b6a9fdf12352a9c5934ca36a4a3311ea/x-pack/solutions/security/plugins/security_solution/server/lib/telemetry/tasks/prebuilt_rule_alerts.ts). It's separate from the [daily snapshot telemetry](https://docs.elastic.dev/telemetry/collection/snapshot-telemetry) we also collect from clusters - that telemetry is mostly used for aggregation data.

We had previously looked into using daily snapshot telemetry for this problem, but given we'd need to collect all relevant alert documents over the 24 hour window it operates in, the method proved too costly and performance intensive.

### Calculating the rule diff for alert objects in snapshot telemetry

Since we already have existing alert telemetry in place, it makes sense to build on top of that without having to start from scratch. Given this, we can start to look at how best to include the customized rule fields into the telemetry data. An easy way to add it would be to [enrich the sanitized alerts](https://github.com/elastic/kibana/blob/06f5a860b6a9fdf12352a9c5934ca36a4a3311ea/x-pack/solutions/security/plugins/security_solution/server/lib/telemetry/tasks/prebuilt_rule_alerts.ts#L93) with a new object listing the customized fields that we can calculate for each alert as fetched. 

However, we immediately run into an issue: the rule diff calculation is an expensive one, already causing multiple performance issues in endpoints that use it. Calling it for each alert in a batch that could contain upwards of 10k alerts would likely prove extremely taxing on performance, possibly even causing timeouts from the telemetry tasks.

The idea was considered to use an internal cache to store the rule assets themselves so that the most cost-intensive part of the rule diff calculation - fetching the rule assets - could be sped up, but it was determined that the size of this cache could also be prohibitively large. We would potentially have to store multiple versions for every prebuilt rule of a library that is growing every month and already contains 1300+ rules.

Given these constraints, the only likely option left is to have the rule diff information already be on the alert document when fetched. This way, we could simply pass it onto the alert telemetry data like the other fields in the allowlist and filter on the relevant fields in our analytics dashboards.

### An overview of the `calculateRuleDiff` function and its performance issues

[Here is where](https://github.com/elastic/kibana/blob/ad48051a98e3c2faab74d5817156841076bc5303/x-pack/solutions/security/plugins/security_solution/server/lib/detection_engine/prebuilt_rules/logic/diff/calculate_rule_diff.ts) the `calculateRuleDiff` function lives just for reference. To begin, we have to fetch both the base version of the rule (from the package itself) and the current implementation of the rule, and then we send these versions into the `calculateRuleDiff` function. 

From there, we convert the rule object to a `DiffableRule` type (similar to the normal rule schema but with certain fields grouped. e.g. `query`, `filters`, and `language` become `kql_query`) and then every field on the rule is compared to determine what, if anything, has changed. There are some more complicated routes taken if we're using this as a true three way diff (what we use when we're upgrading a rule to a new version), but they're not really relevant to what we'd be using this logic for here.

After that we calculate some aggregate stats for the endpoint return value and send back the payload as a `CalculateRuleDiffResult` type containing the full rule diff and rule versions it was derived from.

If we think about this process as two sections, the fetching of rule objects/versions and the diff calculation itself, the more cost intensive one has historically been the fetching of rule objects. When we first built the main routes that currently implement this logic in bulk - the `upgrade/_review` and `upgrade/_perform` endpoints - we didn't have many caps on request size in terms of rules queried. This unbound nature led to a slew of performance and memory issues with both endpoints - a few key ones I've listed below:

- https://github.com/elastic/kibana/issues/208361
- https://github.com/elastic/security-team/issues/11822
- https://github.com/elastic/kibana/issues/208355

The descriptions in these go into a lot more detail about the incidents that were taking place, but, to summarize, we were running into OOM errors and crashes in Kibana due to inefficient logic paths and some duplicated requests which led to big scalability problems. There was also an issue with the size of the package being served by fleet, we had originally wanted it to contain all rule versions (not just the past 3), but it was far too large which is why we shrunk it down to its current size. A lot of these problems were mitigated by the team through various means (caching the routes, paginating the requests, etc.) but the underlying issues with memory consumption and speed still exist when working at scale. We still have open issues on how to handle some of them that will hopefully be worked on soon:

- https://github.com/elastic/kibana/issues/210544
- https://github.com/elastic/kibana/issues/199101

Some of these issues are tied with the endpoints themselves, but the core logic for each, and certainly most of the performance issues, are coming from this `calculateRuleDiff` function and its surrounding dependencies (i.e. fetching rule versions). There's a more [in depth ticket](https://github.com/elastic/kibana/issues/187649) about switching away from the fleet package distribution. This would ideally allow for a much less performance intensive fetching of rule versions and way quicker runtimes, but it has yet to be worked on outside of some initial architecture discussion.

## Problem Statement

We need to establish a method to add which specific rule fields are customized to the alert documents so that the telemetry data is able to visualize which alerts are coming from prebuilt rules with functional fields that have been modified, and filter those alerts in a trivial manner.

## Goals

- This solution should be efficient in performance
  - At some point we will need to do the rule diff calculation, that's unavoidable. Given how much performance trouble it's caused us in the past to do this calculation at scale, we need a way to make sure this doesn't cause performance issues elsewhere in the app or telemetry endpoints.
- This solution needs to be extensible
  - We are inevitably going to add more fields, both functional and non-functional to our rule schema. These fields also need to be easily added to this telemetry calculation, ideally without any additional code being written on the telemetry side of things
- This solution should be quick to implement
  - Given enough time and resources, we could probably create a whole new telemetry system specifically for customized rule fields with the greatest analytics data this company has ever seen. However we don't have all those things and should prioritize using existing tools and telemetry data wherever possible.

## Non-Goals

- Though we want any solution to be extensible, this RFC is not attempting to discuss any specific rule schema changes coming in the future that aren't related to this issue.
- We also want to limit the scope of this solution to *what* has been changed on the rule object, not *how*. Any discussion of the how starts to evolve into the rule auditing conversation which is outside the scope of this feature.

## Rejected Solutions

### Calculating the rule diff during rule execution

This would be similar to the previously discussed idea to calculate rule diffs in the telemetry snapshot, but instead at rule execution time, right before we write the rule object to the alert document. It would be a lot less data to parse through (one rule execution vs 24 hours worth of alerts) but we'd still bump up against similar performance issues mentioned with the daily snapshot - particularly when thinking about this calculation being done for every time a customized rule executes across a whole instance. We'd also run into another performance issue - namely slowing down the rule execution process itself. While the rule diff calculation for a single rule execution wouldn't be too cost prohibitive - especially as we'd be able to use the same rule diff object for all alerts generated by that execution - it would still have performance ramifications for rule execution speed, something we try to maximize when possible. Again thinking about this performance hit, however minor, stretched across every rule execution by every rule customized rule starts to result in a bit larger performance impact than we were comfortable with. 

This was primarily another case of being weary of running the rule diff calculation at scale, something we have seen cause major performance issues in the past. Our solution, in order to be efficient, will only run this calculation when absolutely needed.

### Using a hash of functional fields to quickly compare changes

This solution would have compared a hash of functional fields (most notably query fields) to a hash of the unmodified rule's functional fields to quickly detect any changes in the object. The idea behind this was: instead of fetching whole rule objects to then run the diff calculation on, why not simply fetch a stored hash of unmodified functional fields, quickly hash the current rule's functional fields and compare the two to see if there was any divergence between the two rules? This solution would have been very quick and allowed us to likely run this calculation within the alert snapshot endpoint, but the lack of granularity and rigidness when calculating the stored hashes made us reject this path. The extensibility factor for if/when another functional field was added or changed combined with the need to keep another rule asset-like object stored somewhere was too much complexity to add.

---

## Proposed Solution: Adding a field to the rule schema to track specific customized fields

### Approach and technical details

At its core, this solution is pretty simple: adding a new field to the rule schema that would keep track of which field(s) were customized on the rule object. This would allow us to write the customized field list to the alert object at rule execution the same as we do any rule field, without any runtime calculations that'd slow down rule execution. The field would be updated in the same places `rule_source` is currently updated (basically any CRUD operation on the rule object), and would be either omitted or defaulted to an empty array if a rule's base version didn't exist as there'd be no way to accurately calculate the field list.

This field would be an array and it would contain a list of objects that have . It was considered to have this field be a key/value pair with the key being the field name and the value be the original, unmodified rule field but was rejected. Having the original values would no doubt be helpful in some cases but would also introduce a whole host of new edge cases and potentially double the size of the rule object if most fields were customized. Having the names of the fields customized and whether or not they're functional fields is all we'd need for our use case and some of the previously linked telemetry tickets. Furthermore, the querying of an array within the alerts telemetry cluster would be far more straightforward than querying for keys on an object, as KQL doesn't support the direct querying of object keys and we'd have to rely on wildcard queries or some other syntax. Arrays also allow us to easily chain together multiple clauses in order to be extremely granular with our telemetry analysis. I've listed some example KQL queries below. 

This field would live under the `rule_source` field object. Given its relation to the other fields in this object, it would make sense to consolidate all this logic into one area.

A good name for this field would be `customized_fields` because of the existing language we have in `rule_source` with `is_customized`. It's also a fairly good descriptor of exactly what the field contains.

### Missing base versions

We would also add a boolean field to the `rule_source` object that would specify whether or not the base version of the rule existed during rule source calculation. This would be used to explicitly determine whether or not the rule had all data available to it during calculation or if we were defaulting to the `is_customized: true` state that we do currently when a base version doesn't exist. This field could also be used to filter out telemetry alerts we couldn't determine to have functional changes or not.

### Rule customization diff return value proposal

The value we currently return from the `calculateRuleDiff` function is based off the `DiffableRule` schema - a schema that is similar to our overall detection rule schema but groups certain fields into one (for instance: `query`, `filters`, and `language` become `kql_query`) and omits other fields that we don't intend on diffing (e.g. `exception_list`, `actions`, etc.). This is the implementation currently used for the existing endpoints that run the `calculateRuleDiff` function, most notably the `upgrade/_review` and `upgrade/_perform` routes, but would not be a good return structure for our use case. The grouped fields are essentially an implementation detail and the mixing of the two schemas could cause lots of maintenance pain as well as confusion for consumers of the data on the telemetry side of things. Instead we will need to divide this data up into its original one-to-one field name match with our detection rule schema. 

This work has been done before on the front-end for our per-field rule diff flyout, but proved to be pretty difficult to write due to typing conflicts. Furthermore, extracting the individual fields from the nested, post-diff structure we return from the `calculateRuleDiff` function requires us to essentially compare these grouped fields twice - one during the diffing and then another to know how to extract them out of the diffed result.

In order to properly return these fields I believe some refactoring of the `calculateRuleDiff` will need to be done to somehow return these ungrouped fields during the diffing process so that we aren't repeating comparisions needlessly. This work shouldn't need to change the underlying implemetation of the function in any of these endpoints, and with our current test coverage, I think it would be safe enough to refactor this isolated step within the rule diffing process.

### Functional field definition

A functional field is defined as a field that, when modified, has the ability to change whether or not an alert is generated for the purpose of analyzing how often a rule is generating alerts. There are fields that fully meet these criteria (`query`, `filters`, etc.) but also fields that partially meet this criteria - for instance, the `index` field would obviously change how an alert is written, and changing it would have an impact on what events are queried on, but it's more about changing the rule to suit a user's environment rather than changing the output of the rule itself. For fields like these in this "gray area" between a functional field and a definitively non-functional field (something like `description` which has absolutely no impact on alert generation), we can define as supporting fields: fields that affect rule behavior and operation, but don't change the execution outcome. 

With this definition, we will be conservative in the fields we are defining as "functional" and only the 100%, unarguable fields will be labeled as such. Given we have a list of fields to query on in the telemetry data, alerts can be filtered upon in a more nuanced way on the telemetry side of things if needed.

A full list of fields we diff on with their functional classification is located in the RFC appendix.

### Schema definitions

We will want to map this new field to the existing `rule_source` field mapping. Notably **NOT** as a nested field, as it would constrain us heavily for KQL queries and dashboard tooling later on down the line. 

Putting it all together under one field also makes it very easy to allowlist into the alert telemetry schema they already have without including the rest of the `kibana.alert.rule.parameters` field. Including this whole parameters object could increase the size of the alert document by a lot and wouldn't really add a lot of useful data at scale. Plus, if this data *was* ever needed further down the line, it wouldn't be that difficult to add on the telemetry side of things.

**Mapping example of new rule source object for prebuilt rules**:

```ts
rule_source: {
  type: 'external';
  is_customized: boolean;
  customized_fields: Array<{
    field_name: string;
  }>;
  missing_base_version: boolean;
};
```

The mapping for our detection rules is carried over onto the alert document schema as the flattened `kibana.alert.rule.parameters` field. Changing the rule schema here should carry the same change to the detection alert schema on the kibana side of things.

**Alert telemetry schema**:

We will want to enrich this data in the telemetry pipeline with functional field markers so that we can easily filter on this data on the telemetry side of things. We wait till the telemetry endpoint to do this comparison and enrichment because the information is not needed on the rule object or alert documents themselves - we could always calculate it on the fly if need be later on.

The current implementation of the prebuilt rule alert schema uses [this list](https://github.com/elastic/kibana/blob/0ad59fab8835d67b476ffbdb82850649e70ab4d9/x-pack/solutions/security/plugins/security_solution/server/lib/telemetry/filterlists/prebuilt_rules_alerts.ts) to include alert fields onto the sanitized alert documents. In order to include the `rule_source` object and *not* the rest of the `kibana.alert.rule.parameters` field we would need to include the following mapping:

```ts
'kibana.alert.rule.parameters': {
  rule_source: true,
}
```

We also want to add a field to the alert telemetry schema to contain this enriched data with the functional field comparison. Placing it at the alert framework level as `kibana.alert.rule.customizations` would be a good option. We could define this enriched telemetry-specific schema as such:

```json
"customizations": {
  "customized_fields": ["query", "filters", "name"],
  "num_functional_fields": 2,
  "missing_base_version": false,
}
```

As stated above, the addition of the `num_functional_fields` field in the object would be there primarily for filtering purposes. Having a way to easily filter out all alerts from rules with customized functional fields makes for a better, less error prone method for writing queries than having to chain potentially 20+ field names together. It also helps with the extensibility of these queries, as anytime we add a field to the rule object we wouldn't have to update the telemetry and related dashboards to account for the rule, we'd just have to set it properly on rule update.

We could also add more field counters in the future (e.g. `num_non_functional_fields`) to filter this data in more granular ways. Given the current structure, and the fact it's all implemented entirely within the telemetry pipeline, this work would be fairly straightforward and wouldn't involve any changes to the rule or alert schema.

### Examples

**Example rule object with new field**:

```json
{
    ...
    "rule_source": {
        "type": "external",
        "is_customized": true,
        // New field
        "customized_fields": [
            { "field_name": 'query' },
            { "field_name": 'note' },
            { "field_name": 'tags' },
        ],
        "missing_base_version": false,
    },
    ...
}
```

**Example KQL queries in the alerts telemetry cluster**:

```txt
not (kibana.alert.rule.customizations.num_functional_fields : 0 and kibana.alert.rule.customizations.missing_base_version : false)
```

A query we could use to filter out any alerts generated by prebuilt rules that have functional fields customized and rules that have a missing base version.

### Pros & Cons

Pros:

- Would have a negligible effect on performance
  - We already calculate the rule diff everywhere we'd modify this field, would just need to carry over the field names.
  - No need to run the rule diff calculation at rule execution time, just copy it to the alert object like we do any other field
- Easy to query on the telemetry side
  - Building aggregation visualizations and dashboards in the alert telemetry cluster would be fairly straightforward with this implementation. As shown in some of the examples above, we can be granular and specific with our queries.

Cons:

- Once we add it there's (basically) no going back
  - Not necessarily a con but something to consider in terms of longevity

### Complexity & Cost

This effort would involve:

- adding a new field to our rule schemas
- updating all dependent schemas
- adding the logic to update this field all the same places we update `rule_source`
- writing the new field to the alert documents during rule execution
- writing tests to cover the new field and resulting logic additions

This is all in addition to the then-unblocked telemetry work that could take place once this was implemented.

## Appendix

### Defining functional rule fields

| Rule fields                           | Functional field? |
|---------------------------------------|-------------------|
| `name`                                | no                |
| `description`                         | no                |
| `risk_score`                          | no                |
| `severity`                            | no                |
| `rule_name_override`                  | no                |
| `timestamp_override`                  | no                |
| `timestamp_override_fallback_disabled`| no                |
| `timeline_id`                         | no                |
| `timeline_title`                      | no                |
| `license`                             | no                |
| `note`                                | no                |
| `building_block_type`                 | no                |
| `investigation_fields`                | no                |
| `version`                             | no                |
| `tags`                                | no                |
| `risk_score_mapping`                  | no                |
| `severity_mapping`                    | no                |
| `interval`                            | no                |
| `from`                                | no                |
| `to`                                  | no                |
| `author`                              | no                |
| `false_positives`                     | no                |
| `references`                          | no                |
| `max_signals`                         | no                |
| `threat`                              | no                |
| `setup`                               | no                |
| `related_integrations`                | no                |
| `required_fields`                     | no                |
| `query`                               | yes               |
| `type`                                | yes               |
| `language`                            | yes               |
| `index`                               | no                |
| `data_view_id`                        | no                |
| `filters`                             | yes               |
| `event_category_override`             | yes               |
| `tiebreaker_field`                    | yes               |
| `timestamp_field`                     | yes               |
| `alert_suppression`                   | yes               |
| `saved_id`                            | yes               |
| `threshold`                           | yes               |
| `threat_query`                        | yes               |
| `threat_mapping`                      | yes               |
| `threat_index`                        | no                |
| `threat_filters`                      | yes               |
| `threat_indicator_path`               | no                |
| `threat_language`                     | yes               |
| `anomaly_threshold`                   | yes               |
| `machine_learning_job_id`             | yes               |
| `new_terms_fields`                    | yes               |
| `history_window_start`                | yes               |
