---
id: kibDevTutorialAddingApiCapacityTestingJourney
slug: /kibana-dev-docs/tutorial/performance/adding_api_capacity_testing_journey
title: Adding Api Capacity Testing Journey
summary: Learn how to add api capacity test
date: 2023-01-13
tags: ['kibana', 'onboarding', 'setup', 'performance', 'development', 'telemetry']
---

## Overview
It is important to test individual API endpoint for the baseline performance, scalability, or breaking point. If an API doesn’t meet performance requirements, it is a bottleneck.
This capacity tests track how response time changes while we slowly increase number of concurrent requests per second.
While using similar load model, we are able to identify how many requests per second each endpoint can hold with response time staying below critical threshold.

Capacity API test defines 3 response time thresholds (default ones: 3000, 6000, 12000) in ms. Test results report rps (requests per second) for each threshold.

Test results are reported using EBT in the following format:
```json
{
  "_index": "backing-kibana-server-scalability-metrics-000003",
  "_source": {
    "eventType": "scalability_metric",
    "journeyName": "GET /internal/security/me",
    "ciBuildId": "0185aace-821d-42af-97c7-5b2b029f94df",
    "responseTimeMetric": "85%",
    "kibanaVersion": "8.7.0",
    "threshold1ResponseTime": 3000,
    "rpsAtThreshold1": 586,
    "threshold2ResponseTime": 6000,
    "rpsAtThreshold2": 601,
    "threshold3ResponseTime": 12000,
    "rpsAtThreshold3": 705,
    "warmupAvgResponseTime": 34,
    ...
  }
}
```

### Adding a new test
Create a new json file in `x-pack/test/scalability/apis` with required properties:
- **journeyName** is a test name, e.g. `GET /internal/security/session`
- **scalabilitySetup** is used to set load model
- **testData** is used to populate Elasticsearch and Kibana wth test data
- **streams: `[ {requests: [] }]`** defines the API endpoint(s) to be called

`scalabilitySetup` includes warmup and test phases.
Warmup phase simulates 10 concurrent requests during 30s period and is important to get consistent results in test phase.
Test phase simulates increasing concurrent requests from `minUsersCount` to `maxUsersCount` within `duration` time.
Both `maxUsersCount` and `duration` in test phase should be adjusted for individual endpoint:
  - `maxUsersCount` should be reasonable and enough to reach endpoint limits
  - `duration` should be long enough to ramp up requests with low pace (1-2 requests per second)

Example:
```json
{
  "journeyName": "GET /internal/security/session", 
  "scalabilitySetup": {
    "warmup": [
      {
        "action": "constantUsersPerSec",
        "userCount": 10,
        "duration": "30s"
      }
    ],
    "test": [
      {
        "action": "rampUsersPerSec",
        "minUsersCount": 10,
        "maxUsersCount": 700,
        "duration": "345s"
      }
    ],
    "maxDuration": "8m"
  },
  "testData": {
    "esArchives": [],
    "kbnArchives": []
  },
  "streams": [
    {
      "requests": [
        {
          "http": {
            "method": "GET",
            "path": "/internal/security/session",
            "headers": {
              "Cookie": "",
              "Kbn-Version": "",
              "Accept-Encoding": "gzip, deflate, br",
              "Content-Type": "application/json"
            },
            "statusCode": 200
          }
        }
      ]
    }
  ]
}
```

Override default response time thresholds by adding to `scalabilitySetup`:
```json
  "responseTimeThreshold": {
    "threshold1": 1000,
    "threshold2": 2000,
    "threshold3": 5000
  },
```

### Running api capacity journey locally
Clone [kibana-load-testing](https://github.com/elastic/kibana-load-testing) repo.

Use the Node script from kibana root directory:
  `node scripts/run_scalability_cli.js --journey-path x-pack/test/scalability/apis/$YOUR_JOURNEY_NAME.ts`

Use `--kibana-install-dir` flag to test build

### Benchmarking performance on CI
In order to keep track on performance metrics stability, api capacity tests are run on main branch with a scheduled interval.
Bare metal machine is used to produce results as stable and reproducible as possible.

#### Machine specifications

All benchmarks are run on bare-metal machines with the [following specifications](https://www.hetzner.com/dedicated-rootserver/ex100):

CPU: Intel® Core™ i9-12900K 16 cores
RAM: 128 GB
SSD: 1.92 TB Data center Gen4 NVMe

#### Track performance results
APM metrics are reported to [kibana-stats](https://kibana-stats.elastic.dev/) cluster.
You can filter transactions using labels, e.g. `labels.journeyName : "GET /internal/security/session"`

Custom metrics reported with EBT are available in [Telemetry Staging](https://telemetry-v2-staging.elastic.dev/) cluster, `kibana-performance` space.
