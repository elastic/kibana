[[running-elasticsearch]]
== Running {es} during development

There are many ways to run {es} while you are developing.

[discrete]

=== By snapshot

This will run a snapshot of {es} that is usually built nightly. Read more about <<development-es-snapshots>>.

[source,bash]
----
yarn es snapshot
----
By default, two users are added to Elasticsearch:

  - A superuser with username: `elastic` and password: `changeme`, which can be used to log into Kibana with.
  - A user with username: `kibana_system` and password `changeme`. This account is used by the Kibana server to authenticate itself to Elasticsearch, and to perform certain actions on behalf of the end user. These credentials should be specified in your kibana.yml as described in <<using-kibana-with-security>>

See all available options, like how to specify a specific license, with the `--help` flag.

[source,bash]
----
yarn es snapshot --help
----

`trial` will give you access to all capabilities.

**Keeping data between snapshots**

If you want to keep the data inside your {es} between usages of this command, you should use the following command, to keep your data folder outside the downloaded snapshot folder:

[source,bash]
----
yarn es snapshot -E path.data=../data
----

=== By source

If you have the {es} repo checked out locally and wish to run against that, use `source`. By default, it will reference an {es} checkout which is a sibling to the {kib} directory named elasticsearch. If you wish to use a checkout in another location you can provide that by supplying --source-path 

[source,bash]
----
yarn es source
----

=== From an archive

Use this if you already have a distributable. For released versions, one can be obtained on the {es} downloads page.

[source,bash]
----
yarn es archive <full_path_to_archive>
----

Each of these will run {es} with a basic license. Additional options are available, pass --help for more information.

=== From a remote host

You can save some system resources, and the effort of generating sample data, if you have a remote {es} cluster to connect to. (Elasticians: you do! Check with your team about where to find credentials)

You'll need to create a kibana.dev.yml (<<customize-kibana-yml>>) and add the following to it:

[source,bash]
----
elasticsearch.hosts:
  - {{ url }}
elasticsearch.username: {{ username }}
elasticsearch.password: {{ password }}
elasticsearch.ssl.verificationMode: none
----

If many other users will be interacting with your remote cluster, you'll want to add the following to avoid causing conflicts:

[source,bash]
----
kibana.index: '.{YourGitHubHandle}-kibana'
xpack.task_manager.index: '.{YourGitHubHandle}-task-manager-kibana'
----

==== Running remote clusters

Setup remote clusters for cross cluster search (CCS) and cross cluster replication (CCR).

Start your primary cluster by running:

[source,bash]
----
yarn es snapshot -E path.data=../data_prod1
----

Start your remote cluster by running:

[source,bash]
----
yarn es snapshot -E transport.port=9500 -E http.port=9201 -E path.data=../data_prod2
----

Once both clusters are running, start {kib}. {kib} will connect to the primary cluster.

Setup the remote cluster in {kib} from either Management -> {es} -> Remote Clusters UI or by running the following script in Console.

[source,bash]
----
PUT _cluster/settings
{
  "persistent": {
    "cluster": {
      "remote": {
        "cluster_one": {
          "seeds": [
            "localhost:9500"
          ]
        }
      }
    }
  }
}
----

Follow the cross-cluster search instructions for setting up index patterns to search across clusters (<<management-cross-cluster-search>>).
