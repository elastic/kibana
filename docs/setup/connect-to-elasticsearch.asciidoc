[[connect-to-elasticsearch]]
== Add data

The best way to add data to the Elastic Stack is to use one of our many integrations,
which are pre-packaged assets that are available for a wide array of popular
services and platforms. With integrations, you can add monitoring for logs and
metrics, protect systems from security threats, and more.

All integrations are available in a single view, and
{kib} guides you there from the *Welcome* screen, home page, and main menu.

[role="screenshot"]
image::images/add-integration.png[Integrations page from which you can choose integrations to start collecting and analyzing data]

NOTE: When an integration is available for both
https://www.elastic.co/guide/en/fleet/master/beats-agent-comparison.html[Elastic Agent and Beats],
the *Integrations* view defaults to the
Elastic Agent integration, if it is generally available (GA).
To show a
Beats integration, use the filter below the side navigation.

[float]
=== Add data with Elastic solutions

A good place to start is with one of our Elastic solutions, which
offer experiences for common use cases.

* *Web site search crawler.*
Discover, extract, and index your web content into App Search engines using the
{app-search-ref}/web-crawler.html[Enterprise Search web site crawler].
Search across Google Drive, GitHub, Salesforce, and many other web services using
{workplace-search-ref}/workplace-search-content-sources.html[Workplace Search content sources].

* *Elastic APM.*
Get logs, metrics, traces, and uptime data into the Elastic Stack.
Integrations are available for popular services and platforms,
such as Nginx, AWS, and MongoDB,
and generic input types like log files.
Refer to {observability-guide}/observability-introduction.html[Elastic Observability]
for more information.

* *Endpoint Security.*
Protect your hosts and send logs, metrics, and endpoint security data
to Elastic Security.
Refer to {security-guide}/ingest-data.html[Ingest data to Elastic Security]
for more information.

[float]
=== Add data with programming languages

Add any data to the Elastic Stack using a programming language,
such as JavaScript, Java, Python, and Ruby.
Details for each programming language library that Elastic provides are in the
https://www.elastic.co/guide/en/elasticsearch/client/index.html[{es} Client documentation].

If you are running {kib} on our hosted {es} Service,
click *View deployment details* on the *Integrations* view
to verify your {es} endpoint and Cloud ID, and create API keys for integration.

[float]
=== Add sample data

Sample data sets come with sample visualizations, dashboards, and more to help you
explore {kib} before you add your own data.
In the *Integrations* view, search for *Sample Data*, and then add the type of
data you want.

[role="screenshot"]
image::images/add-sample-data.png[eCommerce, flights, and web logs sample data sets that you can explore in Kibana]

[discrete]
[[upload-data-kibana]]
=== Upload a data file

If you have a log file or delimited CSV, TSV, or JSON file, you can upload it,
view its fields and metrics, and optionally import it into {es}.
In the *Integrations* view, search for *Upload a file*, and then drop your file on the target.

By default, you can upload a file up to 100 MB. This value is configurable up to 1 GB in
<<fileupload-maxfilesize,Advanced Settings>>.

NOTE: The upload feature is not intended for use as part of a repeated production
process, but rather for the initial exploration of your data.

[role="screenshot"]
image::images/add-data-fv.png[Uploading a file in {kib}]

The {stack-security-features} provide roles and privileges that control which
users can upload files. To upload a file in {kib} and import it into an {es}
index, you'll need:

* `manage_pipeline` or `manage_ingest_pipelines` cluster privilege
* `create`, `create_index`, `manage`, and `read` index privileges for the index
* `all` {kib} privileges for *Discover* and *Data Views Management*

You can manage your roles, privileges, and spaces in **{stack-manage-app}**.

[discrete]
=== What's next?

To take your investigation
to a deeper level, use <<discover, **Discover**>> and quickly gain insight to your data:
search and filter your data, get information about the structure of the fields,
and analyze your findings in a visualization.
